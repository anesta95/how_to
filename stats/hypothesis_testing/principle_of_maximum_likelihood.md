The **principle of maximum likelihood** estimates unknown population parameters by maximizing the probablity of the observed data in a sample when:
* the distribution can be explicitly written in terms of the unknown parameters _and_
* the distribution has a distinct maximum

In many scenarios, the principle of maximum likelihood tells us that the sample mean

$\frac{1}{sample\:size}\displaystyle\sum_{j=1}^{sample\:size}X_i$

is the best estimate for the true mean $\mu$, and the sample proportion

$\frac{\text{the number of favorable outcomes}}{\text{the total number of observations}}$

is the best estimate for a true population proportion. These are **point estimates** â€“ population parameter estimates based on data points.

The **principle of maximum likelihood** says that $\frac{N_i}{n}$ gives the best estimate of $p_i$. This is where $p$ is the probablity of an event happening, $i$ is the specific outcome of an event, like rolling a specific number on a die, $N_i$ is the number of times $i$ occured in the sample data, and $n$ is the number of trials/events in the sample/experiment, such as the number of times a die was rolled.