# [Pivoting](https://tidyr.tidyverse.org/articles/pivot.html)

## Introduction 

This vignette describes the use of new `pivot_longer()` and `pivot_wider()` functions. Their goal is to improve the usability of `gather()` and `spread()`, and incorporate state-of-the-art-features found in other packages.

For some time, it's been obvious that there is something fundamentally wrong with the design of `spread()` and `gather()`. Many people don't find the names intuitive and find it hard to remember which direction corresponds to spreading and which to gathering. It also seems surprisingly hard to remember the arguments to these functions, meaning that many people (including me!) have to consult the documentation every time.

There are two important new features inspired by other R packages that have been advancing reshaping in R:

* `pivot_longer()` can work with multiple value variables that may have different types, inspired by the enhanced `melt()` and `dcast()` functions provided by the [data.table](https://github.com/Rdatatable/data.table/wiki) package by Matt Dowle and Arun Srinivasan.

* `pivot_longer()` and `pivot_wider()` can take a data frame that specifies precisely how metadata stored in column names becomes data variables (and vice versa), inspired by the [cdata](https://winvector.github.io/cdata/) package by John Mount and Nina Zumel.

In this vignette you'll learn the key ideas behind `pivot_longer()` and `pivot_wider()` as you see them used to solve a variety of data reshaping challenges ranging from simple to complex.

To begin we'll load some needed packages. In real analysis code, I'd imagine you'd do with the `library(tidyverse)`, but I can't do that here since this vignette is embedded in a package.

```{r}
library(tidyr)
library(dplyr)
library(readr)
```

## Longer
`pivot_longer()` makes datasets **longer** by increasing the number of rows and decreasing the number of columns. I don't believe it makes sense to describe a dataset as being in "long form". Length is a relative term, and you can only say (e.g.) that dataset A is longer than dataset B.

`pivot_longer()` is commonly needed to tidy wild-caught datasets as they often optimize for ease of data entry or ease of comparison rather than ease of analysis. The following sections show how to use `pivot_longer()` for a wide range of realistic datasets.

### String data in column names
The `relig_income` dataset stores counts based on a survey which (among other things) 

```{r} relig_income```

This dataset contains three variables:

* `religion`, stored in the rows,
* `income` spread across the column names, and
* `count` stored in the cell values.

To tidy it we use `pivot_longer()`:

```{r}
relig_income %>%
    pivot_longer(
        cols = !religion,
        names_to = "income",
        values_to = "count"
    )
```

* The first argument is the dataset to reshape, `relig_income`.

* `cols` describes which columns need to be reshaped. In this case, it's every column apart from `religion`.

* `names_to` gives the name of the variable that will be created from the data stored in the column names, i.e. `income`.

* `values_to` gives the name of the variable that will be created from the data stored in the cell value, i.e. `count`.

Neither the `names_to` nor the `values_to` column exists in `relig_income`, so we provide them as strings surrounded by quotes.

### Numeric data in column names.

The `billboard` dataset records the billboard rank of songs in the year 2000. It has a form similar to the `relig_income` data, but the data encoded in the column names is really an number, not a string.

```{r} billboard```

We can start with the same basic specification as for the `relig_income` dataset. Here we want the names to become a variable called `week`, and the values to become a variable called `rank`. I also use `values_drop_na` to drop rows that correspond to missing values. Not every song stays in the charts for all 76 weeks, so the structure of the input data force the creation of unnecessary explicit `NA`s.

```{r}
billboard %>%
    pivot_longer(
        cols = starts_with("wk"),
        names_to = "week",
        values_to = "rank",
        values_drop_na = TRUE
    )
```

It would be nice to easily determine how long each song stayed in the charts, but to do that, we'll need to convert the `week` variable to an integer. We can do that by using two additional arguments: `names_prefix` strips off the `wk` prefix, and `names_transform` converts `week` into a column with an `integer` data type:

```{r}
billboard %>%
    pivot_longer(
        cols = starts_with("wk"),
        names_to = "week",
        names_prefix = "wk",
        names_transform = as.integer,
        values_to = "rank",
        values_drop_na = TRUE
    )
```

Alternatively, you could do this with a single argument by using `readr::parse_number()` which automatically strips non-numeric components:

```{r}
billboard %>%
    pivot_longer(
        cols = starts_with("wk"),
        names_to = "week",
        names_transform = readr::parse_number,
        values_to = "rank",
        values_drop_na = TRUE
    )
```

### Many variables in column names

A more challenging situation occurs when you have multiple variables crammed into the column names. For example, take the `who` dataset:

```{r} who```

`country`, `iso2`, `iso3`, and `year` are already variables, so they can be left as is. But the columns from `new_sp_m014` to `newrel_f65` encode four variables in their names:

* The `new_`/`new` prefix indicates these are counts of new cases. This dataset only contains new cases, so we'll ignore it here because it's constant.

* `sp`/`rel`/`ep` describe how the case was diagnosed.

* `m`/`f` gives the gender

* `014`/`1524`/`2535`/`3544`/`4554`/`65` supplies the age range.

We can break these variables up by specifying multiple column names in `names_to`, and then either providing `names_sep` or `names_pattern`. Here `names_pattern` is the most natural fit. It has a similar interface to `extract`: you give it a regular expression containing groups (defined by `()`) and it puts each group in a column.

```{r} 
who %>%
    pivot_longer(
        cols = new_sp_m014:newrel_f65,
        names_to = c("diagnosis", "gender", "age"),
        names_pattern = "new_?(.*)_(.)(.*)",
        values_to = "count"
    )
```

We could go one step further and use readr functions to convert the gender and age columns to factors. I think this is good practice when you have a categorical variables with a known set of values.

```{r}
who %>%
    pivot_longer(
        cols = new_sp_m014:newrel_f65,
        names_to = c("diagnosis", "gender", "age"),
        names_pattern = "new_?(.*)_(.)(.*)",
        names_transform = list(
            gender = ~readr::parse_factor(.x, levels = c("f", "m")),
            age = ~readr::parse_factor(
                .x, 
                levels = c("014", "1524", "2534", "3544", "4554", "5564", "65"),
                ordered = TRUE
                )
        ),
        values_to = "count"
    )
```

Doing it this way is a little more efficient than doing a mutate after the fact, `pivot_longer()` only has to transform one occurance of each name where a `mutate()` would need to transform many repetitions.

### Multiple observations per row

So far, we have been working with data frames that have one observation per row, but many important pivoting problems involve multiple observations per row. You can usually recognize this case because the name of the column that you want to appear in the output is part of the column name in the input. In this section, you'll learn how to pivot this sort of data.

The following example is adapted from the [data.table vignette](https://cran.r-project.org/package=data.table/vignettes/datatable-reshape.html) as inspiration for tidyr's solution to this problem.

```{r}household```

Note that we have two pieces of information (or values) for each child: their `name` and their `dob` (date of birth). These need to go into separate columns in the result. Again we supply multiple variables to `names_to`, using `names_sep` to split up each variable name. Note the special name `.value`: this tells `pivot_longer()` that that part of the column name specifies the "value" being measured (which will become a variable in the output).

```{r}
household %>%
    pivot_longer(
        cols = !family,
        names_to = c(".value", "child"),
        names_sep = "_",
        values_drop_na = TRUE
    )
```

Note the use of `values_drop_na = TRUE`: the input shape forces the creation of explicit missing variables for observations that don't exist.

A similar problem also exists in the `anscombe` dataset built into base R:

```{r} anscombe```

This dataset contains four pairs of variables (`x1` and `y1`, `x2` and `y2`, etc.) that underlie Anscombe's quartet, a collection of four datasets that have the same summary statistics (mean, sd, correlation, etc.) but have quite different data. We want to produce a dataset with columns `set`, `x`, and `y`.

```{r}
anscombe %>%
    pivot_longer(
        cols = everything(),
        cols_vary = "slowest",
        names_to = c(".value", "set"),
        names_pattern = "(.)(.)"
    )
```

Setting `cols_vary` to `"slowest"` groups the values from the columns `x1` and `y1` together in the rows of the output before moving on to `x2` and `y2`. This arguement often produces more intuitively ordered output when you are pivoting every column in your dataset.

A similar situation can arise with panel data. For example, take this dataset provided by [Thomas Leeper](https://github.com/leeper/rio/issues/193). We can tidy it using the same approach as for `anscombe`:

```{r}
pnl <- tibble(
    x = 1:4,
    a = c(1, 1, 0, 0),
    b = c(0, 1, 1, 1),
    y1 = rnorm(4),
    y2 = rnorm(4),
    z1 = rep(3, 4),
    z2 = rep(-2, 4)
)

pnl %>%
    pivot_longer(
        cols = !c(x, a, b),
        names_to = c(".value", "time"),
        names_pattern = "(.)(.)"
    )
```

## Wider

`pivot_wider()` is the opposite of `pivot_longer()`: it makes a dataset **wider** by increasing the number of columns and decreasing the number of rows. It's relatively rare to need `pivot_wider()` to make tidy data, but it's often useful for creating summary tables for presentation, or data in a format needed by other tools.

### Capture-recapture data

The `fish_encounters` dataset contributed by [Myfanwy Johnson](https://fishsciences.github.io/post/visualizing-fish-encounter-histories/), describes when fish swimming down a river are detected by automatic monitoring stations:

```{r} fish_encounters```

Many tools used to analyze this data need it in a form where each station is a column:

```{r}
fish_encounters %>%
    pivot_wider(
        names_from = station,
        values_from = seen
    )
```

This dataset only records when a fish was detected by the station - it doesn't record when it wasn't detected (this is common with this type of data). That means the output data is filled with `NA`s. However, in this case we know that the absence of a record means that the fish was not `seen`, so we can ask `pivot_wider()` to fill these missing values in with zeros:

```{r}
fish_encounters %>%
    pivot_wider(
        names_from = station,
        values_from = seen,
        values_fill = 0
    )
```

### Aggregation

You can also use `pivot_wider()` to perform simple aggregation. For example, take the `warpbreaks` dataset built in to base R (converted to a tibble for the better print method):

```{r}
warpbreaks <- warpbreaks %>%
    as_tibble() %>%
    select(wool, tension, breaks)
warpbreaks
```

This is a designed experiment wtih nine replicates for every combination of `wool` (`A` and `B`) and `tension` (`L`, `M`, `H`):

```{r}
warpbreaks %>%
    count(wool, tension)
```

What if we attempt to pivot the levels of `wool` into the columns?

```{r}
warpbreaks %>%
    pivot_wider(
        names_from = wool,
        values_from = breaks
    )
```

We get a warning that each cell in the output corresponds to multiple cells in the input. The default behavior producwees list-columns, which contain all the individual values. A more useful output would be summary statistics, e.g. `mean` breaks for each combination of wool and tension:

```{r}
warpbreaks %>%
    pivot_wider(
        names_from = wool,
        values_from = breaks,
        values_fn = mean
    )
```

For more complex summary operations, I recommend summarizing before reshaping, but for simple cases it's often convenient to summarize within `pivot_wider()`.

### Generate column names from multiple variables

Imagine, as in [this case](https://stackoverflow.com/questions/24929954), that we have information containing the combination of product, country, and year. In tidy form it might look like this:

```{r}
production <- expand_grid(
    product = c("A", "B"),
    country = c("AI", "EI"),
    year = 2000:2014
) %>%
    filter((product == "A" & country == "AI") | product == "B") %>%
    mutate(production = rnorm(nrow(.)))

production
```

We want to widen the data so we have one column for each combination of `product` and `country`. The key is to specify multiple variables for `names_from`:

```{r}
production %>%
    pivot_wider(
        names_from = c(product, country),
        values_from = production
    )
```

When either `names_from` or `values_from` select multiple variables, you can control how the column names in the output are constructed with `names_sep` and `names_prefix`, or the workhorse `names_glue`:

```{r}
production %>%
    pivot_wider(
        names_from = c(product, country),
        values_from = production,
        names_sep = ".",
        names_prefix = "prod."
    )

production %>%
    pivot_wider(
        names_from = c(product, country),
        values_from = production,
        names_glue = "prod_{product}_{country}"
    )
```

### Tidy census

