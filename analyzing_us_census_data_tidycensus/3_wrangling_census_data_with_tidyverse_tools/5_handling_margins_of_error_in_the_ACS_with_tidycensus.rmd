# [3.5 Handling margins of error in the American Community Survey with tidycensus](https://walker-data.com/census-r/wrangling-census-data-with-tidyverse-tools.html#handling-margins-of-error-in-the-american-community-survey-with-tidycensus)

A topic of critical importance when working with data from the American Community Survey is the _margin of error_. 
As opposed to the decennial US Census, which is based on a complete enumeration of the US population, 
the ACS is based on a sample with estimates characterized by margins of error. 
By default, MOEs are returned at a 90 percent confidence level. 
This can be translated roughly as "we are 90 percent sure that the true value 
falls within a range defined by the estimate plus or minus the margin of error."

As discussed in Chapter 2, **tidycensus** takes an opinionated approach to margins of error. 
When applicable, **tidycensus** will always return the margin of error associated with an estimate, 
and does not have an option available to return estimates only. 
For "tidy" or long-form data, these margins of error will be found in the `moe` column; 
for wide-form data, margins of error will be found in columns with an `M` suffix.

The confidence level of the MOE can be controlled with the `moe_level` argument 
in `get_acs()`. The default `moe_level` is `90`, which is what the Census Bureau returns by default. 
tidycensus can also return MOEs at a confidence level of `95` or `99` which uses 
Census Bureau-recommended formulas to adjust the MOE. 
For example, we might look at data on median household income by county in 
Rhode Island using the default `moe_level` of `90`:

```{r}
get_acs(
  geography = "county",
  state = "Rhode Island",
  variables = "B19013_001",
  year = 2020
)
```

A stricter margin of error will increase the size of the MOE relative to its estimate.

```{r}
get_acs(
  geography = "county",
  state = "Rhode Island",
  variables = "B19013_001",
  year = 2020,
  moe_level = 99
)
```


## 3.5.1 Calculating derived margins of error in tidycensus

For small geographies or small populations, margins of error can get quite large, 
in some cases exceeding their corresponding estimates. In the example below, 
we can examine data on age groups by sex for the population age 65 and older for 
Census tracts in Salt Lake County, Utah. We will first generate a vector of 
variable IDs for which we want to request data from the ACS using some base R functionality.

In this workflow, an analyst has used `load_variables()` to look up the variables 
that represent estimates for populations age 65 and up; 
this includes `B01001_020` through `B01001_025` for males, 
and `B01001_044` through `B01001_049` for females. 
Typing out each variable individually would be tedious, 
so an analyst can use string concatenation to generate the required vector of variable IDs as follows:

```{r}
vars <- paste0("B01001_0", c(20:25, 44:49))
vars
```

The resulting variables object, named `vars`, can now be used to request variables in a call to `get_acs()`.

```{r}
salt_lake <- get_acs(
  geography = "tract",
  variables = vars,
  state = "Utah",
  county = "Salt Lake",
  year = 2020
)
```

We will now want to examine the margins of error around the estimates in the returned data. 
Let’s focus on a specific Census tract in Salt Lake County using `filter()`:

```{r}
example_tract <- salt_lake %>%
  filter(GEOID == "49035100100")

example_tract %>% 
  select(-NAME)
```

In many cases, the margins of error exceed their corresponding estimates. 
For example, the ACS data suggest that in Census tract `49035100100`, 
for the male population age 85 and up (variable ID `B01001_0025`), 
there are anywhere between 0 and 45 people in that Census tract. 
This can make ACS data for small geographies problematic for planning and analysis purposes.

A potential solution to large margins of error for small estimates in the ACS is 
to aggregate data upwards until a satisfactory margin of error to estimate ratio is reached. 
The US Census Bureau publishes formulas for appropriately calculating margins of 
error around such derived estimates, which are included in tidycensus with the following functions:

* `moe_sum()`: calculates a margin of error for a derived sum;
* `moe_product()`: calculates a margin of error for a derived product;
* `moe_ratio()`: calculates a margin of error for a derived ratio;
* `moe_prop()`: calculates a margin of error for a derived proportion.

In their most basic form, these functions can be used with constants. 
For example, let’s say we had an ACS estimate of 25 with a margin of error of 5 around that estimate. 
The appropriate denominator for this estimate is 100 with a margin of error of 3. 
To determine the margin of error around the derived proportion of 0.25, we can use `moe_prop()`:

```{r}
moe_prop(25, 100, 5, 3)
```

Our margin of error around the derived estimate of 0.25 (25 / 100) is approximately 0.049.

## 3.5.2 Calculating group-wise margins of error

These margin of error functions in **tidycensus** can in turn be integrated into 
tidyverse-centric analytic pipelines to handle large margins of error around estimates. 
Given that the smaller age bands in the Salt Lake City dataset are characterized by 
too much uncertainty for our analysis, we decide in this scenario to aggregate our 
data upwards to represent populations aged 65 and older by sex.

In the code below, we use the `case_when()` function to create a new column, sex, 
that represents a mapping of the variables we pulled from the ACS to their sex categories. 
We then employ a familiar `group_by() %>% summarize()` method to aggregate our data by Census 
tract and sex. Notably, the call to `summarize()` includes a call to tidycensus’s `moe_sum()` function, 
which will generate a new column that represents the margin of error around the derived sum.

```{r}
salt_lake_grouped <- salt_lake %>% 
  mutate(sex = case_when(
    str_sub(variable, start = -2) < "26" ~ "Male",
    T ~ "Female"
  )) %>% 
  group_by(GEOID, sex) %>% 
  summarize(sum_est = sum(estimate),
            sum_moe = moe_sum(moe, estimate))
```

The margins of error relative to their estimates are now much more reasonable than in the disaggregated data.

That said, the [Census Bureau issues a note of caution](https://www2.census.gov/programs-surveys/acs/tech_docs/statistical_testing/2019_Instructions_for_Stat_Testing_ACS.pdf?): 

> All derived MOE methods are approximations and users should be cautious in using them. 
This is because these methods do not consider the correlation or covariance between the basic estimates. 
They may be overestimates or underestimates of the derived estimate’s standard error 
depending on whether the two basic estimates are highly correlated in either the 
positive or negative direction. 
As a result, the approximated standard error may not match direct calculations of 
standard errors or calculations obtained through other methods.

This means that your "best bet" is to first search the ACS tables to see if your 
data are found in aggregated form elsewhere before doing the aggregation and 
MOE estimation yourself. In many cases, you’ll find aggregated information in 
the ACS combined tables, Data Profile, or Subject Tables that will 
include pre-computed margins of error for you.