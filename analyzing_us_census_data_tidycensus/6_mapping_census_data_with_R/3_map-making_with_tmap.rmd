# [6.3 Map-making with tmap](https://walker-data.com/census-r/mapping-census-data-with-r.html#map-making-with-tmap)

The tmap package (Tennekes 2018) is an excellent alternative for mapping in R that includes a wide range of functionality for custom cartography.

To begin, obtain race and ethnicity data from the 2020 decennial US Census using 
the `get_decennial()` function. We’ll be looking at data on non-Hispanic white, 
non-Hispanic Black, Asian, and Hispanic populations for Census tracts in 
Hennepin County, Minnesota.

```{r}
library(tidycensus)
library(dplyr)

hennepin_race <- get_decennial(
  geography = "tract",
  state = "MN",
  county = "Hennepin",
  variables = c(
    Hispanic = "P2_002N",
    White = "P2_005N",
    Black = "P2_006N",
    Native = "P2_007N",
    Asian = "P2_008N"
  ),
  summary_var = "P2_001N",
  year = 2020,
  geometry = T
) %>% 
  mutate(percent = 100 * (value / summary_value))
```

What's returned is ACS data in tidycensus’s regular “tidy” or long format, 
which will be useful in a moment for comparative map-making, and calculated
group percentages. To get started mapping this data, extract a single 
group from the dataset to illustrate how tmap works.

## 6.3.1 Choropleth maps with tmap
**tmap**’s map-making syntax will be somewhat familiar to users of **ggplot2**, 
as it uses the concept of _layers_ to specify modifications to the map. 
The map object is initialized with `tm_shape()`, which then allows us to view the 
Census tracts with `tm_polygons()`. We’ll first filter our long-form spatial 
dataset to get a unique set of tract polygons, then visualize them.


```{r}
library(tmap)

hennepin_black <- filter(hennepin_race, variable == "Black")

tm_shape(hennepin_black) + tm_polygons()
```
We get a default view of Census tracts in Hennepin County, Minnesota. 
Alternatively the `tm_fill()` function can be used to produce choropleth maps,
as illustrated in the ggplot2 examples above.

```{r}
tm_shape(hennepin_black) + tm_polygons(col = "percent")
```

You’ll notice that **tmap** uses a classed color scheme rather than the continuous palette used by **ggplot2**, by default. This involves the identification of “classes” in the distribution of data values and mapping a color from a color palette to data values that belong to each class. The default classification scheme used by `tm_fill()` is `"pretty"`, which identifies clean-looking intervals in the data based on the data range. In this example, data classes change every 20 percent. However, this approach will always be sensitive to the distribution of data values. Let’s take a look at our data distribution to understand why:

```{r}
hist(hennepin_black$percent)
```

As the histogram illustrates, most Census tracts in Hennepin County have Black populations below 20 percent. In turn, variation within this bucket is not visible on the map given that most tracts fall into one class. The `style` argument in `tm_fill()` supports a number of other methods for classification, including quantile breaks (`"quantile"`), equal intervals (`"equal"`), and Jenks natural breaks (`"jenks"`). Let’s switch to quantiles below, where each class will contain the same number of Census tracts. We can also change the color palette and add some contextual text as we did with ggplot2.

```{r}
tm_shape(hennepin_black) +
  tm_polygons(col = "percent",
              style = "quantile",
              n = 5,
              palette = "Purples",
              title = "2020 US Census") +
  tm_layout(title = "Percent Black\nby Census tract",
            frame = F,
            legend.outside = T) 
```
Switching from the default classification scheme to quantiles reveals additional neighborhood-level heterogeneity in Hennepin County’s Black population in suburban areas. However, it does mask some heterogeneity in Minneapolis as the top class now includes values ranging from 21 percent to 88 percent. 

A “compromise” solution commonly used in GIS cartography applications is the Jenks natural-breaks method, which uses an algorithm to identify meaningful breaks in the data for bin boundaries. 

To assist with understanding how the different classification methods work, the `legend.hist` argument in `tm_polygons()` can be set to `TRUE`, adding a histogram to the map with bars colored by the values used on the map.

```{r}
tm_shape(hennepin_black) +
  tm_polygons(col = "percent",
              style = "jenks",
              n = 5,
              palette = "Purples",
              title = "2020 US Census",
              legend.hist = T) +
  tm_layout(title = "Percent Black\nby Census tract",
            frame = F,
            legend.outside = T,
            bg.color = "grey70",
            legend.hist.width = 5,
            fontfamily = "Verdana")
```
The `tm_layout()` function is used to customize the styling of the map and histogram, and has many more options beyond those shown that can be viewed in the function’s documentation.

## 6.3.2 Adding reference elements to a map


## 6.3.3 Choosing a color palette
The examples shown in this chapter thus far have used a variety of color palettes to display statistical variation on choropleth maps. So how do you go about choosing an appropriate color palette? There are a variety of considerations to take into account.

First, it is important to understand the type of data you are working with. If your data are _quantitative_ - that is, expressed with numbers, which you’ll commonly be working with using Census data - you’ll want a color palette that can show the statistical variation in your data correctly. In the demographic examples shown above, decennial Census data range from a low value to a high value. This type of information is effectively represented with a _sequential_ color palette. **Sequential** color palettes use either a single hue or related hues then modify the color lightness or intensity to generate a sequence of colors. An example single-hue palette is the “Purples” ColorBrewer palette used in the map above.

With this palette, lighter colors should generally be used to represent lower data values, and darker values should represent higher values, suggesting a greater density/concentration of that attribute. In other color palettes, however, the more intense colors may be the lighter colors and should be used accordingly to represent data values. This is the case with the popular viridis color palettes, implemented in R with the **viridis** package.

**Diverging** color palettes are best used when the cartographer wants to highlight extreme values on either end of the data distribution and represent neutral values in the middle. 

For Census data mapping, diverging palettes are well-suited to maps that visualize change over time. A map of population change using a diverging palette would highlight extreme population loss and extreme population gain with intense colors on either end of the palette, and represent minimal population change with a muted, neutral color in the middle.


**Qualitative** palettes are appropriate for categorical data, as they represent data values with unique, unordered hues. 

While maps of Census data as returned by **tidycensus** will generally use sequential or diverging color palettes (given the quantitative nature of Census data), derived data products may require qualitative palettes.

Choosing an appropriate color palette for your maps can be a challenge. Fortunately, the ColorBrewer and viridis palettes are appropriate for a wide range of cartographic use cases and have built-in support in **ggplot2** and **tmap**. An excellent tool for helping decide on a color palette is **tmap**’s Palette Explorer app, accessible with the command `tmaptools::palette_explorer()`. Run this command in your R console to launch an interactive app that helps you explore different color scenarios using ColorBrewer and viridis palettes. Notably, the app includes a color blindness simulator to help you choose color palettes that are color blindness friendly.

## 6.3.4 Alternative map types with tmap
Choropleth maps are a core part of the Census data analyst’s toolkit, but they are not ideal for every application. In particular, choropleth maps are best suited for visualizing rates, percentages, or statistical values that are normalized for the population of areal units. They are not ideal when the analyst wants to compare counts (or estimated counts) themselves, however. Choropleth maps of count data may ultimately reflect the underlying size of a baseline population; additionally, given that the counts are compared visually relative to the irregular shape of the polygons, choropleth maps can make comparisons difficult.

### 6.3.4.1 Graduated symbols
An alternative commonly used to visualize count data is the **graduated symbol map**. 
Graduated symbol maps use shapes referenced to geographic units that are sized 
relative to a data attribute. The example below uses **tmap**’s `tm_bubbles()` function 
to create a graduated symbol map of the Black population in Hennepin County, 
mapping the `estimate` column.

```{r}
tm_shape(hennepin_black) +
  tm_polygons() +
  tm_bubbles(size = "value", alpha = 0.5, col = "navy", 
             title.size = "Non-Hispanic Black via 2020 US Census") +
  tm_layout(legend.outside = T,
            legend.outside.position = "bottom")
```
The visual comparisons on the map are made between the circles, not the polygons themselves, reflecting differences between population sizes.

### 6.3.4.2 Faceted maps
Given that the long-form race & ethnicity dataset returned by tidycensus includes information on five groups, a cartographer may want to visualize those groups comparatively. A single choropleth map cannot effectively visualize five demographic attributes simultaneously, and creating five separate maps can be tedious. A solution to this is using _faceting_.

Faceted maps in *tmap* are created with the `tm_facets()` function. 
The `by` argument specifies the column to be used to identify unique groups in the data. 
The remaining code is familiar **tmap** code; in this example, `tm_fill()` is 
preferred to `tm_polygons()` to hide the Census tract borders given the smaller 
sizes of the maps. The legend is also moved with the legend.position argument in 
`tm_layout()` to fill the empty space in the faceted map.

```{r}
tm_shape(hennepin_race) +
  tm_facets(by = "variable", scale.factor = 4) +
  tm_fill(col = "percent",
          style = "quantile",
          n = 6,
          palette = "Blues",
          title = "Percent (2020 US Census)") +
  tm_layout(bg.color = "gray",
            legend.position = c(-.7, .15),
            panel.label.bg.color = "white")
```
Faceted maps in tmap are created with the tm_facets() function. The by argument specifies the column to be used to identify unique groups in the data. The remaining code is familiar tmap code; in this example, tm_fill() is preferred to tm_polygons() to hide the Census tract borders given the smaller sizes of the maps. The legend is also moved with the legend.position argument in tm_layout() to fill the empty space in the faceted map.

#### 6.3.4.3 Dot-density maps
Dot-density maps scatter dots within areal units relative to the size of a data attribute. This cartographic method is intended to show attribute density through the dot distributions; for a Census map, in areas where the dots are dense, more people live there, whereas sparsely positioned dots reflect sparsity of population. Dot-density maps can also incorporate categories in the data to visualize densities of different subgroups simultaneously.

The `as_dot_density()` function in **tidycensus** helps users get Census data ready for dot-density visualization. For an input dataset, the function requires specifying a `value` column that represents the data attribute to be visualized, and a `values_per_dot` value that determines how many data values each dot should represent. The `group` column then partitions dots by group and shuffles their visual ordering on the map so that no one group occludes other groups.

In this example, we specify `value = "estimate"` to visualize the data from the 2020 US Census; `values_per_dot = 100` for a data to dots ratio of 100 people per dot; and `group = "variables"` to partition dots by racial / ethnic group on the map.

```{r}
hennepin_dots <- hennepin_race %>% 
  as_dot_density(
    value = "value",
    values_per_dot = 100,
    group = "variable"
  )
```
The map itself is created with the `tm_dots()` function, which in this example is combined with a background map using `tm_polygons()` to show the relative racial and ethnic heterogeneity of Census tracts in Hennepin County.

```{r}
background_tracts <- filter(hennepin_race, variable == "White")

tm_shape(background_tracts) +
  tm_polygons(col = "white",
              border.col = "gray") +
  tm_shape(hennepin_dots) +
  tm_dots(col = "variable",
          palette = "Set1",
          size = .005,
          title = "1 dot per 100 people") +
  tm_layout(legend.outside = T,
            title = "Race/ethnicity,\n2020 US Census")
```
Issues with dot-density maps can include overplotting of dots which can make legibility a problem; experiment with different dot sizes and dots to data ratios to improve this. Additionally, the use of Census tract polygons to generate the dots can cause visual issues. As dots are placed randomly within Census tract polygons, they in many cases will be placed in locations where no people live (such as lakes in Hennepin County). Dot distributions will also follow tract boundaries, which can create an artificial impression of abrupt changes in population distributions along polygon boundaries (as seen on the example map). 

A solution is the [dasymetric dot-density map](https://doi.org/10.3138/cart.53.3.2017-0021), which first removes areas from polygons which are known to be uninhabited then runs the dot-generation algorithm over those modified areas. `as_dot_density()` includes an argument, `erase_water`, that will automatically remove water areas from the input shapes before generating dots, avoiding dot placement in large bodies of water. This technique uses the `erase_water()` function in the **tigris** package.